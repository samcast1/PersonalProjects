{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bf4ae9",
   "metadata": {},
   "source": [
    "#### Why batch? \n",
    "\n",
    "Batches can be calculated in parallel. This is typically done on GPUs rather than CPUs. \n",
    "\n",
    "Allows a certain generalization of input features rather than tuning a model piecewise to single sets of parameters in series. In other words, batch learning gives a more stable model over time.\n",
    "\n",
    "That said, showing all samples at once instead of batches will probably result in overfitting. Typicaly batch sizes are 32, 64 or maybe 128."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04b308",
   "metadata": {},
   "source": [
    "#### Coding a batch of inputs taken from four neurons over time to three destination neurons. \n",
    "\n",
    "Implements the matrix product: output matrix consists of dot products of corresponding rows and columns of weights and inputs. \n",
    "\n",
    "In other words, first element of output matrix is dot product between first row of matrix A and first column of matrix B. Second element is dot prod between first row of matrix A and second column of matrix B. When all columns of matrix B are exhausted, output matrix begins second row and proceeds to record dot products of second row of matrix A with all columns of matrix B, so on and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b77cc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Recall: size at index[1] of first element in dot product needs to match size of index[0] of second element. \n",
    "# in order to do this, we have to switch the rows an columns of the weights matrix. \n",
    "# Switching rows and columns is done by Transpose. This can be done on np arrays.\n",
    "\n",
    "inputs = [[1,2,3,2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases= [2,3,0.5]\n",
    "\n",
    "\n",
    "output = np.dot(inputs, np.array(weights).T) + biases # in this case, inputs needs to come first.\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae544e",
   "metadata": {},
   "source": [
    "#### Adding another layer. \n",
    "\n",
    "Need another set of weights and biases.\n",
    "\n",
    "This looks like 4 neurons -> 3 neurons -> 3 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f9ea43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185  2.18525]\n",
      " [ 0.2434  -2.7332   2.0687 ]\n",
      " [-0.99314  1.41254  0.88425]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [[1,2,3,2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2,3,0.5]\n",
    "\n",
    "# second layer\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "           [-0.5, 0.12, -0.33],\n",
    "           [0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1,2,-0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62059f34",
   "metadata": {},
   "source": [
    "#### It's better to convert concept of layers into an object. \n",
    "\n",
    "Denote input features with X.\n",
    "\n",
    "We need to initialize weights as random values between -1 and +1, but tighter ranges are generally better. In this case, we'll go for between -0.1 and +0.1.\n",
    "\n",
    "Initialize weights using np.random.randn, which gives a gaussian distribution around 0. \n",
    "\n",
    "Biases are typically initialied as 0, but that can result in dead networks.\n",
    "\n",
    "To this end, it helps to normalize and scale input dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f78f74a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17640523  0.04001572  0.0978738 ]\n",
      " [ 0.22408932  0.1867558  -0.09772779]\n",
      " [ 0.09500884 -0.01513572 -0.01032189]\n",
      " [ 0.04105985  0.01440436  0.14542735]]\n"
     ]
    }
   ],
   "source": [
    "# Quick run of np.random.randn to understand how I initialize weights:\n",
    "\n",
    "print(0.10*np.random.randn(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "364b5aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 output: \n",
      "\n",
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
      "\n",
      "Layer 2 output: \n",
      "\n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = [[1,2,3,2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "# define hidden layers\n",
    "# will need to know number of initial inputs and number of neurons in destination\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        \n",
    "        # np.random.randn params are the desired output shape\n",
    "        # first param is size of input coming in\n",
    "        # second param is number of neurons in destination\n",
    "        \n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons) # order reversed from prev examples to avoid transposition\n",
    "        \n",
    "        # Will need one bias for each neuron in destination, shape is 1D\n",
    "        # np.zeros first param IS the shape of desired output, so input as tuple\n",
    "        \n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "# input size = number of features in each sample. In this case, 4\n",
    "# number of neurons = any number you want\n",
    "# only req is that input size for layer2 is the output size of layer1\n",
    "\n",
    "layer1 = Layer_Dense(4,5)\n",
    "layer2 = Layer_Dense(5,2)\n",
    "\n",
    "layer1.forward(X)\n",
    "print(\"Layer 1 output: \")\n",
    "print()\n",
    "print(layer1.output)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Layer 2 output: \")\n",
    "print()\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba3f1e",
   "metadata": {},
   "source": [
    "#### The rows above represent output activations for each sample, i.e. each batch in the input. X had 3 samples, so outputs have 3 rows.\n",
    "#### The columns represent output activations for each neuron in the destination layer. Layer one had 5 destination neurons and Layer two had 2 destination neurons.\n",
    "#### The next thing: *Activation functions!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc55899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
